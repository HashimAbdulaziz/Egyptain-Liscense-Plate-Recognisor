{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10797074,"sourceType":"datasetVersion","datasetId":6701045},{"sourceId":10797086,"sourceType":"datasetVersion","datasetId":6701056},{"sourceId":10841693,"sourceType":"datasetVersion","datasetId":6732939},{"sourceId":264092,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":225900,"modelId":247660}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:46:58.897658Z","iopub.execute_input":"2025-02-24T14:46:58.897973Z","iopub.status.idle":"2025-02-24T14:46:59.346818Z","shell.execute_reply.started":"2025-02-24T14:46:58.897950Z","shell.execute_reply":"2025-02-24T14:46:59.346069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:46:59.980360Z","iopub.execute_input":"2025-02-24T14:46:59.980941Z","iopub.status.idle":"2025-02-24T14:47:07.756387Z","shell.execute_reply.started":"2025-02-24T14:46:59.980910Z","shell.execute_reply":"2025-02-24T14:47:07.755541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nfrom IPython.display import display, Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:47:33.883763Z","iopub.execute_input":"2025-02-24T14:47:33.884082Z","iopub.status.idle":"2025-02-24T14:47:40.349025Z","shell.execute_reply.started":"2025-02-24T14:47:33.884058Z","shell.execute_reply":"2025-02-24T14:47:40.348345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install roboflow\n\n# from roboflow import Roboflow\n# rf = Roboflow(api_key=\"DTywvqb9qrh51hE7n9XR\")\n# project = rf.workspace(\"roboflow-universe-projects\").project(\"license-plate-recognition-rxg4e\")\n# version = project.version(6)\n# dataset = version.download(\"yolov11\")\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.407286Z","iopub.execute_input":"2025-02-20T20:11:23.407707Z","iopub.status.idle":"2025-02-20T20:11:23.410797Z","shell.execute_reply.started":"2025-02-20T20:11:23.407683Z","shell.execute_reply":"2025-02-20T20:11:23.409931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!yolo task=detect mode=train model=yolo11n.pt data='/kaggle/working/License-Plate-Recognition-6/data.yaml' epochs=100 imgsz=640 device=0,1 batch=128 project=/kaggle/working/runs name=train_results save_period=25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.411684Z","iopub.execute_input":"2025-02-20T20:11:23.411911Z","iopub.status.idle":"2025-02-20T20:11:23.428994Z","shell.execute_reply.started":"2025-02-20T20:11:23.411892Z","shell.execute_reply":"2025-02-20T20:11:23.428353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# # Define the path to the train_results3 folder\n# folder_path = '/kaggle/working/runs/train_results3'\n\n# # Get a list of all image files in the folder\n# image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Load and display images in separate figures\n# for image_file in image_files:\n#     # Load the image\n#     img_path = os.path.join(folder_path, image_file)\n#     img = Image.open(img_path)\n    \n#     # Create a new figure for each image\n#     plt.figure(figsize=(8, 6))\n#     plt.imshow(img)\n#     plt.title(os.path.basename(img_path))\n#     plt.axis('off')\n#     plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.429696Z","iopub.execute_input":"2025-02-20T20:11:23.429907Z","iopub.status.idle":"2025-02-20T20:11:23.442755Z","shell.execute_reply.started":"2025-02-20T20:11:23.429888Z","shell.execute_reply":"2025-02-20T20:11:23.442167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Step 1: Install Required Libraries\n# !pip install ultralytics matplotlib pillow\n\n# # Step 2: Import Libraries\n# import os\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# import math\n\n# # Step 3: Define Paths\n# weights_path = '/kaggle/working/runs/train_results3/weights/best.pt'  # Path to your trained weights\n# dataset_path = '/kaggle/input/egy-carsv1/Egy_Cars_Imgs'  # Path to the dataset folder containing test images\n# output_path = '/kaggle/working/predictions1'   # Path to save prediction outputs\n\n# # Create the output directory if it doesn't exist\n# os.makedirs(output_path, exist_ok=True)\n\n# # Step 4: Run Inference Using YOLO\n# # Use the yolo command to run predictions with your trained weights\n# !yolo task=detect mode=predict model={weights_path} source={dataset_path} project={output_path} name=predictions\n\n# # Step 5: Display Predicted Images in a Grid\n# # Get a list of all predicted image files in the output folder\n# predicted_images_dir = os.path.join(output_path, 'predictions')\n# image_files = [f for f in os.listdir(predicted_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Define grid parameters\n# images_per_row = 5  # Number of images per row\n# num_images = len(image_files)\n# num_rows = math.ceil(num_images / images_per_row)  # Calculate number of rows\n\n# # Create a grid of subplots\n# fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 4 * num_rows))\n# axes = axes.flatten()  # Flatten the axes array for easy iteration\n\n# # Load and display images in the grid\n# for i, ax in enumerate(axes):\n#     if i < num_images:  # Only process valid image indices\n#         try:\n#             # Load the image\n#             img_path = os.path.join(predicted_images_dir, image_files[i])\n#             img = Image.open(img_path)\n            \n#             # Display the image\n#             ax.imshow(img)\n#             ax.set_title(os.path.basename(img_path), fontsize=10)\n#             ax.axis('off')  # Turn off axis for better visualization\n#         except Exception as e:\n#             ax.set_title(\"Error loading image\", fontsize=10)\n#             ax.axis('off')\n#             print(f\"Error loading image {img_path}: {e}\")\n#     else:\n#         # Hide unused subplots\n#         ax.axis('off')\n\n# # Adjust layout to prevent overlap\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.443565Z","iopub.execute_input":"2025-02-20T20:11:23.443780Z","iopub.status.idle":"2025-02-20T20:11:23.461795Z","shell.execute_reply.started":"2025-02-20T20:11:23.443752Z","shell.execute_reply":"2025-02-20T20:11:23.461080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Step 3: Define Paths\n# weights_path = '/kaggle/working/runs/train_results3/weights/best.pt'  # Path to your trained weights\n# dataset_path = '/kaggle/input/egy-platesv1/Egy_Plates_Imgs'  # Path to the dataset folder containing test images\n# output_path = '/kaggle/working/predictions2'   # Path to save prediction outputs\n\n# # Create the output directory if it doesn't exist\n# os.makedirs(output_path, exist_ok=True)\n\n# # Step 4: Run Inference Using YOLO\n# # Use the yolo command to run predictions with your trained weights\n# !yolo task=detect mode=predict model={weights_path} source={dataset_path} project={output_path} name=predictions\n\n# # Step 5: Display Predicted Images in a Grid\n# # Get a list of all predicted image files in the output folder\n# predicted_images_dir = os.path.join(output_path, 'predictions')\n# image_files = [f for f in os.listdir(predicted_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Define grid parameters\n# images_per_row = 5  # Number of images per row\n# num_images = len(image_files)\n# num_rows = math.ceil(num_images / images_per_row)  # Calculate number of rows\n\n# # Create a grid of subplots\n# fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 4 * num_rows))\n# axes = axes.flatten()  # Flatten the axes array for easy iteration\n\n# # Load and display images in the grid\n# for i, ax in enumerate(axes):\n#     if i < num_images:  # Only process valid image indices\n#         try:\n#             # Load the image\n#             img_path = os.path.join(predicted_images_dir, image_files[i])\n#             img = Image.open(img_path)\n            \n#             # Display the image\n#             ax.imshow(img)\n#             ax.set_title(os.path.basename(img_path), fontsize=10)\n#             ax.axis('off')  # Turn off axis for better visualization\n#         except Exception as e:\n#             ax.set_title(\"Error loading image\", fontsize=10)\n#             ax.axis('off')\n#             print(f\"Error loading image {img_path}: {e}\")\n#     else:\n#         # Hide unused subplots\n#         ax.axis('off')\n\n# # Adjust layout to prevent overlap\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.462527Z","iopub.execute_input":"2025-02-20T20:11:23.462721Z","iopub.status.idle":"2025-02-20T20:11:23.479666Z","shell.execute_reply.started":"2025-02-20T20:11:23.462704Z","shell.execute_reply":"2025-02-20T20:11:23.478940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"DTywvqb9qrh51hE7n9XR\")\nproject = rf.workspace(\"ealprainshams\").project(\"ealpr-awask\")\nversion = project.version(1)\ndataset = version.download(\"yolov11\")\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:11:23.481148Z","iopub.execute_input":"2025-02-20T20:11:23.481350Z","iopub.status.idle":"2025-02-20T20:11:37.322700Z","shell.execute_reply.started":"2025-02-20T20:11:23.481332Z","shell.execute_reply":"2025-02-20T20:11:37.321659Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!yolo task=detect mode=train model=/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt data='/kaggle/working/EALPR-1/data.yaml' epochs=50 imgsz=640 device=0,1 batch=128 project=/kaggle/working/runs name=fine_tuned_results save_period=25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T20:19:04.472725Z","iopub.execute_input":"2025-02-20T20:19:04.473102Z","iopub.status.idle":"2025-02-20T20:55:58.874020Z","shell.execute_reply.started":"2025-02-20T20:19:04.473075Z","shell.execute_reply":"2025-02-20T20:55:58.872997Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# # Define the path to the train_results3 folder\n# folder_path = '/kaggle/working/runs/fine_tuned_results'\n\n# # Get a list of all image files in the folder\n# image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Load and display images in separate figures\n# for image_file in image_files:\n#     # Load the image\n#     img_path = os.path.join(folder_path, image_file)\n#     img = Image.open(img_path)\n    \n#     # Create a new figure for each image\n#     plt.figure(figsize=(8, 6))\n#     plt.imshow(img)\n#     plt.title(os.path.basename(img_path))\n#     plt.axis('off')\n#     plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T21:00:09.560777Z","iopub.execute_input":"2025-02-20T21:00:09.561189Z","iopub.status.idle":"2025-02-20T21:00:19.206302Z","shell.execute_reply.started":"2025-02-20T21:00:09.561154Z","shell.execute_reply":"2025-02-20T21:00:19.205459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Install Required Libraries\n!pip install ultralytics matplotlib pillow\n\n# Step 2: Import Libraries\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport math\n\n# Step 3: Define Paths\nweights_path = '/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt'  # Path to your trained weights\ndataset_path = '/kaggle/input/egy-carsv1'  # Path to the dataset folder containing test images\noutput_path = '/kaggle/working/predictions'   # Path to save prediction outputs\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_path, exist_ok=True)\n\n# Step 4: Run Inference Using YOLO\n# Use the yolo command to run predictions with your trained weights\nprint(\"Running YOLO inference...\")\n!yolo task=detect mode=predict model={weights_path} source={dataset_path} project={output_path} name=predictions\n\n# Step 5: Verify Predictions Folder\npredicted_images_dir = os.path.join(output_path, 'predictions')\nif not os.path.exists(predicted_images_dir):\n    print(f\"Error: Predictions folder '{predicted_images_dir}' not found.\")\nelse:\n    # Get a list of all predicted image files in the output folder\n    image_files = [f for f in os.listdir(predicted_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n    if not image_files:\n        print(\"No predicted images found in the folder.\")\n    else:\n        # Step 6: Display Predicted Images in a Grid\n        num_images = len(image_files)\n        images_per_row = 5  # Number of images per row\n        num_rows = math.ceil(num_images / images_per_row)  # Calculate number of rows\n\n        # Create a grid of subplots\n        fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 4 * num_rows))\n        axes = axes.flatten()  # Flatten the axes array for easy iteration\n\n        # Load and display images in the grid\n        for i, ax in enumerate(axes):\n            if i < num_images:  # Only process valid image indices\n                try:\n                    # Load the image\n                    img_path = os.path.join(predicted_images_dir, image_files[i])\n                    img = Image.open(img_path)\n                    \n                    # Display the image\n                    ax.imshow(img)\n                    ax.set_title(os.path.basename(img_path), fontsize=10)\n                    ax.axis('off')  # Turn off axis for better visualization\n                except Exception as e:\n                    ax.set_title(\"Error loading image\", fontsize=10)\n                    ax.axis('off')\n                    print(f\"Error loading image {img_path}: {e}\")\n            else:\n                # Hide unused subplots\n                ax.axis('off')\n\n        # Adjust layout to prevent overlap\n        plt.tight_layout()\n\n        # Save the grid as an image file in /kaggle/working/\n        output_grid_path = '/kaggle/working/output_grid.png'\n        plt.savefig(output_grid_path, bbox_inches='tight', pad_inches=0.1)\n        print(f\"Grid saved to {output_grid_path}\")\n\n        # Display the grid in the notebook\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:14:51.587399Z","iopub.execute_input":"2025-02-24T15:14:51.587747Z","iopub.status.idle":"2025-02-24T15:15:07.249512Z","shell.execute_reply.started":"2025-02-24T15:14:51.587722Z","shell.execute_reply":"2025-02-24T15:15:07.248525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Step 3: Define Paths\n# weights_path = '/kaggle/working/runs/fine_tuned_results/weights/best.pt'  # Path to your trained weights\n# dataset_path = '/kaggle/input/egy-platesv1/Egy_Plates_Imgs'  # Path to the dataset folder containing test images\n# output_path = '/kaggle/working/predictions2'   # Path to save prediction outputs\n\n# # Create the output directory if it doesn't exist\n# os.makedirs(output_path, exist_ok=True)\n\n# # Step 4: Run Inference Using YOLO\n# # Use the yolo command to run predictions with your trained weights\n# !yolo task=detect mode=predict model={weights_path} source={dataset_path} project={output_path} name=predictions\n\n# # Step 5: Display Predicted Images in a Grid\n# # Get a list of all predicted image files in the output folder\n# predicted_images_dir = os.path.join(output_path, 'predictions')\n# image_files = [f for f in os.listdir(predicted_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# # Define grid parameters\n# images_per_row = 5  # Number of images per row\n# num_images = len(image_files)\n# num_rows = math.ceil(num_images / images_per_row)  # Calculate number of rows\n\n# # Create a grid of subplots\n# fig, axes = plt.subplots(num_rows, images_per_row, figsize=(20, 4 * num_rows))\n# axes = axes.flatten()  # Flatten the axes array for easy iteration\n\n# # Load and display images in the grid\n# for i, ax in enumerate(axes):\n#     if i < num_images:  # Only process valid image indices\n#         try:\n#             # Load the image\n#             img_path = os.path.join(predicted_images_dir, image_files[i])\n#             img = Image.open(img_path)\n            \n#             # Display the image\n#             ax.imshow(img)\n#             ax.set_title(os.path.basename(img_path), fontsize=10)\n#             ax.axis('off')  # Turn off axis for better visualization\n#         except Exception as e:\n#             ax.set_title(\"Error loading image\", fontsize=10)\n#             ax.axis('off')\n#             print(f\"Error loading image {img_path}: {e}\")\n#     else:\n#         # Hide unused subplots\n#         ax.axis('off')\n\n# # Adjust layout to prevent overlap\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T21:05:39.876971Z","iopub.execute_input":"2025-02-20T21:05:39.877297Z","iopub.status.idle":"2025-02-20T21:05:48.940338Z","shell.execute_reply.started":"2025-02-20T21:05:39.877273Z","shell.execute_reply":"2025-02-20T21:05:48.938376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nfrom ultralytics import YOLO\nimport matplotlib.pyplot as plt\n\n# Step 1: Load the trained YOLO model\nmodel_path = '/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt'\nmodel = YOLO(model_path)\n\n# Step 2: Define the folder containing images\nimage_folder = '/kaggle/input/egycar-vs-distance/plate_Vs_distance'\n\n# Step 3: Initialize lists to store distances and confidence scores\ndistances = []\nconfidence_scores = []\n\n# Step 4: Process each image in the folder\nfor filename in os.listdir(image_folder):\n    if filename.endswith('.jpg') or filename.endswith('.png'):\n        # Extract distance from the filename\n        distance = int(filename.split('m')[0])\n        \n        # Load the image\n        image_path = os.path.join(image_folder, filename)\n        image = cv2.imread(image_path)\n        \n        # Run inference\n        results = model.predict(source=image, save=False, imgsz=640)\n        \n        # Extract confidence scores for license plate detections\n        confidences = [float(conf) for conf in results[0].boxes.conf.cpu().numpy()]\n        boxes = results[0].boxes.xyxy.cpu().numpy()\n        \n        # Assuming there is only one license plate per image, take the highest confidence score\n        if confidences:\n            max_confidence = max(confidences)\n            distances.append(distance)\n            confidence_scores.append(max_confidence)\n            \n            # Display the image with the detected bounding box and confidence score\n            for box, conf in zip(boxes, confidences):\n                x_min, y_min, x_max, y_max = map(int, box)\n                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n                cv2.putText(image, f\"Confidence: {conf:.2f}\", (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n            \n            # Convert BGR to RGB for displaying with matplotlib\n            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            plt.figure(figsize=(10, 6))\n            plt.imshow(image_rgb)\n            plt.title(f'Distance: {distance}m, Confidence: {max_confidence:.2f}')\n            plt.axis('off')\n            plt.show()\n        else:\n            print(f\"No license plate detected in image at {distance}m\")\n\n# Step 5: Plot distance vs. confidence\nplt.figure(figsize=(10, 6))\nplt.plot(distances, confidence_scores, marker='o', linestyle='-', color='b')\nplt.title('License Plate Detection Confidence vs. Distance')\nplt.xlabel('Distance (m)')\nplt.ylabel('Confidence Score')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:56:58.876034Z","iopub.execute_input":"2025-02-24T14:56:58.876430Z","iopub.status.idle":"2025-02-24T14:56:59.092884Z","shell.execute_reply.started":"2025-02-24T14:56:58.876397Z","shell.execute_reply":"2025-02-24T14:56:59.092029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\nimport matplotlib.pyplot as plt\n\n# Load the pre-trained model\nmodel = YOLO(\"/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt\")\n\n# Define the path to the images directory\nimages_dir = '/kaggle/input/egycar-vs-distance/plate_Vs_distance'\n\n# List all image files in the directory\nimage_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Extract distances from filenames (assuming filenames are formatted as \"Xm.jpg\" where X is the distance)\ndistances = [int(f.split('m')[0]) for f in image_files]\nimage_paths = [os.path.join(images_dir, f) for f in image_files]\n\n# Perform inference on each image\nresults = []\nfor img_path in image_paths:\n    result = model(img_path)\n    results.append(result)\n\n# Calculate accuracy for each image\naccuracies = []\nfor i, result in enumerate(results):\n    # Check if any license plates were detected\n    if len(result[0].boxes) > 0:\n        accuracies.append(1)  # License plate detected\n    else:\n        accuracies.append(0)  # No license plate detected\n\n# Create a scatter plot of distance vs. accuracy\nplt.scatter(distances, accuracies)\nplt.xlabel('Distance (m)')\nplt.ylabel('Accuracy')\nplt.title('Distance vs. Accuracy')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:35:03.626709Z","iopub.execute_input":"2025-02-24T15:35:03.627020Z","iopub.status.idle":"2025-02-24T15:35:05.293580Z","shell.execute_reply.started":"2025-02-24T15:35:03.626998Z","shell.execute_reply":"2025-02-24T15:35:05.292542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# Create a scatter plot\nplt.scatter([1, 2, 3], [4, 5, 6])\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Test Plot')\nplt.show()  # This is necessary to display the plot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T15:40:43.323848Z","iopub.execute_input":"2025-02-24T15:40:43.324166Z","iopub.status.idle":"2025-02-24T15:40:43.475536Z","shell.execute_reply.started":"2025-02-24T15:40:43.324142Z","shell.execute_reply":"2025-02-24T15:40:43.474633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\nimport matplotlib.pyplot as plt\n\n# Ensure plots are displayed inline\n%matplotlib inline\n\n# Load the pre-trained model\nmodel = YOLO(\"/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt\")\n\n# Define the path to the images directory\nimages_dir = '/kaggle/input/egycar-vs-distance/plate_Vs_distance'\n\n# List all image files in the directory\nimage_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Extract distances from filenames (assuming filenames are formatted as \"Xm.jpg\" where X is the distance)\ndistances = [int(f.split('m')[0]) for f in image_files]\nimage_paths = [os.path.join(images_dir, f) for f in image_files]\n\n# Perform inference on each image\nresults = []\nfor img_path in image_paths:\n    result = model(img_path)\n    results.append(result)\n\n# Calculate accuracy for each image\naccuracies = []\nfor i, result in enumerate(results):\n    # Check if any license plates were detected\n    if len(result[0].boxes) > 0:\n        accuracies.append(1)  # License plate detected\n    else:\n        accuracies.append(0)  # No license plate detected\n\n# Debugging: Print distances and accuracies\nprint(\"Distances:\", distances)\nprint(\"Accuracies:\", accuracies)\n\n# Create a scatter plot of distance vs. accuracy\nplt.scatter(distances, accuracies)\nplt.xlabel('Distance (m)')\nplt.ylabel('Accuracy')\nplt.title('Distance vs. Accuracy')\nplt.grid(True)\nplt.show()\n\n# Save the plot as a file (optional)\nplt.savefig('distance_vs_accuracy.png')  # Fixed the missing closing quote\nplt.close()\n\n# Display the saved plot (optional)\nfrom IPython.display import Image\nImage(filename='distance_vs_accuracy.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:05:16.696598Z","iopub.execute_input":"2025-02-24T16:05:16.696921Z","iopub.status.idle":"2025-02-24T16:05:17.248862Z","shell.execute_reply.started":"2025-02-24T16:05:16.696899Z","shell.execute_reply":"2025-02-24T16:05:17.247723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Install Required Libraries\n!pip install ultralytics matplotlib pillow\n\n# Step 2: Import Libraries\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\n\n# Step 3: Define Paths\nweights_path = '/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt'  # Path to your trained weights\ndataset_path = '/kaggle/input/egycar-vs-distance/plate_Vs_distance'  # Path to the dataset folder containing test images\noutput_path = '/kaggle/working/predictions'   # Path to save prediction outputs\n\n# Create the output directory if it doesn't exist\nos.makedirs(output_path, exist_ok=True)\n\n# Step 4: Run Inference Using YOLO\n# Use the yolo command to run predictions with your trained weights\nprint(\"Running YOLO inference...\")\n!yolo task=detect mode=predict model={weights_path} source={dataset_path} project={output_path} name=predictions\n\n# Step 5: Verify Predictions Folder\npredicted_images_dir = os.path.join(output_path, 'predictions5')\nif not os.path.exists(predicted_images_dir):\n    print(f\"Error: Predictions folder '{predicted_images_dir}' not found.\")\nelse:\n    # Get a list of all predicted image files in the output folder\n    image_files = [f for f in os.listdir(predicted_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    if not image_files:\n        print(\"No predicted images found in the folder.\")\n    else:\n        # Load the YOLO model for inference\n        from ultralytics import YOLO\n        model = YOLO(weights_path)\n\n        # Process each image\n        for image_file in image_files:\n            try:\n                # Load the image\n                img_path = os.path.join(predicted_images_dir, image_file)\n                img = cv2.imread(img_path)\n                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for matplotlib\n\n                # Run inference on the image\n                results = model.predict(source=img_path, save=False, imgsz=640)\n\n                # Extract detections\n                boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n                confidences = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n\n                # Display the image without annotations\n                plt.figure(figsize=(10, 6))\n                plt.imshow(img_rgb)\n                plt.title(f\"Image: {image_file}\", fontsize=12)\n                plt.axis('off')\n                plt.show()\n\n                # Print results for the image\n                print(f\"Results for {image_file}:\")\n                for i, (box, conf) in enumerate(zip(boxes, confidences)):\n                    x_min, y_min, x_max, y_max = map(int, box)\n                    print(f\"  Detection {i + 1}: BBox=[{x_min}, {y_min}, {x_max}, {y_max}], Confidence={conf:.2f}\")\n\n            except Exception as e:\n                print(f\"Error processing image {image_file}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:24:09.769019Z","iopub.execute_input":"2025-02-24T16:24:09.769423Z","iopub.status.idle":"2025-02-24T16:24:20.930553Z","shell.execute_reply.started":"2025-02-24T16:24:09.769392Z","shell.execute_reply":"2025-02-24T16:24:20.929461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install opencv-python-headless ultralytics numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T01:11:59.572569Z","iopub.execute_input":"2025-03-02T01:11:59.572790Z","iopub.status.idle":"2025-03-02T01:12:04.855399Z","shell.execute_reply.started":"2025-03-02T01:11:59.572761Z","shell.execute_reply":"2025-03-02T01:12:04.854366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\nif torch.cuda.is_available():\n    print(\"GPU is available!\")\n    device = torch.device(\"cuda\")  # Use GPU\nelse:\n    print(\"GPU is not available, using CPU instead.\")\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T01:18:22.676589Z","iopub.execute_input":"2025-03-02T01:18:22.676833Z","iopub.status.idle":"2025-03-02T01:18:26.114687Z","shell.execute_reply.started":"2025-03-02T01:18:22.676801Z","shell.execute_reply":"2025-03-02T01:18:26.113763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics opencv-python-headless numpy matplotlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T02:09:40.942647Z","iopub.execute_input":"2025-03-02T02:09:40.943011Z","iopub.status.idle":"2025-03-02T02:09:44.357906Z","shell.execute_reply.started":"2025-03-02T02:09:40.942986Z","shell.execute_reply":"2025-03-02T02:09:44.356855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom ultralytics import YOLO\nfrom IPython.display import Image, display\n\n# Step 1: Define the deskewing function\ndef deskew(image):\n    \"\"\"\n    Deskew the image to align text horizontally.\n    :param image: Input image.\n    :return: Deskewed image.\n    \"\"\"\n    coords = np.column_stack(np.where(image > 0))\n    angle = cv2.minAreaRect(coords)[-1]\n    if angle < -45:\n        angle = -(90 + angle)\n    else:\n        angle = -angle\n    (h, w) = image.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n    return rotated\n\n# Step 2: Load the trained YOLO model\nmodel_path = '/kaggle/input/lisence-plate-detector-weights/tensorflow2/default/1/best.pt'\nmodel = YOLO(model_path)\n\n# Step 3: Download and load the input image\nimage_url = '/kaggle/input/egycar-vs-distance/plate_Vs_distance/3m.jpeg'\nimage_path = '/kaggle/input/egycar-vs-distance/plate_Vs_distance/3m.jpeg'\n\n# Download the image\n!wget -q {image_url} -O {image_path}\n\n# Load the image using OpenCV\noriginal_image = cv2.imread(image_path)\nif original_image is None:\n    print(\"Error: Failed to load the image.\")\nelse:\n    print(\"Step 1: Original Image Loaded Successfully\")\n    display(Image(filename=image_path))  # Display the original image\n\n    # Step 4: Run inference to detect license plates\n    results = model.predict(source=image_path, save=False, imgsz=640)\n\n    # Extract bounding boxes from the results\n    boxes = results[0].boxes.xyxy.cpu().numpy()  # Get bounding box coordinates\n    confidences = results[0].boxes.conf.cpu().numpy()  # Get confidence scores\n    class_ids = results[0].boxes.cls.cpu().numpy()  # Get class IDs\n\n    print(f\"\\nStep 2: Detected {len(boxes)} objects in the image.\")\n\n    # Step 5: Process each detected region\n    for i, box in enumerate(boxes):\n        # Extract bbox coordinates\n        x_min, y_min, x_max, y_max = map(int, box)\n        confidence = confidences[i]\n        class_id = int(class_ids[i])\n\n        print(f\"\\nProcessing Detection {i + 1}:\")\n        print(f\"  Class ID: {class_id}, Confidence: {confidence:.2f}\")\n        print(f\"  Bounding Box: [x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}]\")\n\n        # Crop the detected region\n        cropped_region = original_image[y_min:y_max, x_min:x_max]\n        cropped_path = f'/kaggle/working/cropped_region_{i}.jpg'\n        cv2.imwrite(cropped_path, cropped_region)  # Save the cropped region\n        print(\"\\nStep 3: Cropped Region\")\n        display(Image(filename=cropped_path))  # Display the cropped region\n\n        # Convert to grayscale\n        gray_img = cv2.cvtColor(cropped_region, cv2.COLOR_BGR2GRAY)\n        gray_path = f'/kaggle/working/gray_image_{i}.jpg'\n        cv2.imwrite(gray_path, gray_img)  # Save the grayscale image\n        print(\"\\nStep 4: Grayscale Image\")\n        display(Image(filename=gray_path))  # Display the grayscale image\n\n        # Apply thresholding\n        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n        binary_path = f'/kaggle/working/binary_image_{i}.jpg'\n        cv2.imwrite(binary_path, binary_img)  # Save the binary image\n        print(\"\\nStep 5: Binary Image (Thresholded)\")\n        display(Image(filename=binary_path))  # Display the binary image\n\n        # Remove noise using morphological operations\n        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n        cleaned_img = cv2.morphologyEx(binary_img, cv2.MORPH_CLOSE, kernel)\n        cleaned_path = f'/kaggle/working/cleaned_image_{i}.jpg'\n        cv2.imwrite(cleaned_path, cleaned_img)  # Save the cleaned image\n        print(\"\\nStep 6: Cleaned Image (Noise Removed)\")\n        display(Image(filename=cleaned_path))  # Display the cleaned image\n\n        # Deskew the image\n        deskewed_img = deskew(cleaned_img)\n        deskewed_path = f'/kaggle/working/deskewed_image_{i}.jpg'\n        cv2.imwrite(deskewed_path, deskewed_img)  # Save the deskewed image\n        print(\"\\nStep 7: Deskewed Image (Text Aligned)\")\n        display(Image(filename=deskewed_path))  # Display the deskewed image\n\n        # Resize the image\n        resized_img = cv2.resize(deskewed_img, (300, 75))  # Resize to standard dimensions\n        resized_path = f'/kaggle/working/resized_image_{i}.jpg'\n        cv2.imwrite(resized_path, resized_img)  # Save the resized image\n        print(\"\\nStep 8: Resized Image\")\n        display(Image(filename=resized_path))  # Display the resized image\n\n        # Enhance contrast using histogram equalization\n        enhanced_img = cv2.equalizeHist(resized_img)\n        enhanced_path = f'/kaggle/working/enhanced_image_{i}.jpg'\n        cv2.imwrite(enhanced_path, enhanced_img)  # Save the enhanced image\n        print(\"\\nStep 9: Enhanced Image (Contrast Improved)\")\n        display(Image(filename=enhanced_path))  # Display the enhanced image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T02:29:38.594027Z","iopub.execute_input":"2025-03-02T02:29:38.594391Z","iopub.status.idle":"2025-03-02T02:29:39.036019Z","shell.execute_reply.started":"2025-03-02T02:29:38.594366Z","shell.execute_reply":"2025-03-02T02:29:39.034932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}